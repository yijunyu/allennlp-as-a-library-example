docker build -t allen docker
if [ ! -f train.jsonl -o ! -f dev.jsonl ]; then
#	wget https://s3-us-west-2.amazonaws.com/allennlp/datasets/academic-papers-example/train.jsonl
#	wget https://s3-us-west-2.amazonaws.com/allennlp/datasets/academic-papers-example/dev.jsonl
#	wget https://bitbucket.org/fayola21-lero/farsec47/raw/eab43bb110e531c422b958989a22b5987c641ad4/resources/data/scrubbed/Chromium.csv
	awk -f preprocess.awk Chromium.csv | head -27960 > train.jsonl
	awk -f preprocess.awk Chromium.csv | tail -13980 > dev.jsonl
fi
if [ ! -f glove.6B.100d.txt.gz ]; then
	wget https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.6B.100d.txt.gz
fi
mkdir -p output
docker run -v $PWD:/allennlp -v $PWD/output:/tmp -e /allennlp -p 8000:8000 -it --rm allen sh -c "cd /allennlp && ./run.py train experiments/venue_classifier.json -s /tmp/allennlp"
docker run -v $PWD:/allennlp -v $PWD/output:/tmp -e /allennlp -p 8000:8000 -it --rm allen sh -c "cd /allennlp && ./run.py evaluate --archive_file /tmp/allennlp/model.tar.gz --evaluation-data-file ./dev.jsonl"
